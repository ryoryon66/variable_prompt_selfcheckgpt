{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data_sampled/same/same_query_temperature_0.01_sample_n_30_11_22_02_12_28.csv',\n",
       " '../data_sampled/same/same_query_temperature_0.05_sample_n_30_11_21_17_33_50.csv',\n",
       " '../data_sampled/same/same_query_temperature_0.10_sample_n_30_01_17_13_14_55.csv',\n",
       " '../data_sampled/same/same_query_temperature_0.20_sample_n_30_01_17_08_06_13.csv',\n",
       " '../data_sampled/same/same_query_temperature_0.30_sample_n_30_11_21_08_41_52.csv',\n",
       " '../data_sampled/same/same_query_temperature_0.40_sample_n_30_01_18_07_06_54.csv',\n",
       " '../data_sampled/same/same_query_temperature_0.50_sample_n_30_11_21_01_50_46.csv',\n",
       " '../data_sampled/same/same_query_temperature_0.60_sample_n_30_01_18_14_45_30.csv',\n",
       " '../data_sampled/same/same_query_temperature_0.70_sample_n_30_11_20_00_56_40.csv',\n",
       " '../data_sampled/same/same_query_temperature_0.80_sample_n_30_01_19_14_09_00.csv',\n",
       " '../data_sampled/same/same_query_temperature_0.90_sample_n_30_11_20_08_16_25.csv']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob \n",
    "import os\n",
    "from tkinter import CHAR\n",
    "\n",
    "\n",
    "samples_paths = glob.glob(f\"../data_sampled/same/*\")\n",
    "samples_paths.sort()\n",
    "samples_paths\n",
    "# os.path.basename(samples_paths[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATED_PATH = \"../construct_dataset/df_JAQKET_qa_annot1.csv\"\n",
    "SAMPLES_PATHS = samples_paths\n",
    "NUM_SAMPLES = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running same_query_temperature_0.01_sample_n_30_11_22_02_12_28 (1/11)\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|█████████████████████████████████████████| 200/200 [01:14<00:00,  2.69it/s]\n",
      "the auc-roc is {'pr': 0.490364277320799, 're': 0.4893360752056405, 'f1': 0.4888366627497063, 'ave': 0.48854289071680373, 'random': 0.5105757931844889}\n",
      "Running same_query_temperature_0.05_sample_n_30_11_21_17_33_50 (2/11)\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|█████████████████████████████████████████| 200/200 [01:24<00:00,  2.36it/s]\n",
      "the auc-roc is {'pr': 0.6174206815511164, 're': 0.6089894242068155, 'f1': 0.6109870740305523, 'ave': 0.6111045828437134, 'random': 0.4928319623971798}\n",
      "Running same_query_temperature_0.10_sample_n_30_01_17_13_14_55 (3/11)\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|█████████████████████████████████████████| 200/200 [01:44<00:00,  1.91it/s]\n",
      "the auc-roc is {'pr': 0.6722385428907167, 're': 0.6618977673325499, 'f1': 0.6643066980023501, 'ave': 0.665246768507638, 'random': 0.5309048178613396}\n",
      "Running same_query_temperature_0.20_sample_n_30_01_17_08_06_13 (4/11)\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|█████████████████████████████████████████| 200/200 [01:59<00:00,  1.67it/s]\n",
      "the auc-roc is {'pr': 0.7007931844888368, 're': 0.687749706227967, 'f1': 0.6924500587544065, 'ave': 0.6929200940070506, 'random': 0.4332549941245593}\n",
      "Running same_query_temperature_0.30_sample_n_30_11_21_08_41_52 (5/11)\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|█████████████████████████████████████████| 200/200 [02:03<00:00,  1.62it/s]\n",
      "the auc-roc is {'pr': 0.7204465334900116, 're': 0.709165687426557, 'f1': 0.7131022326674501, 'ave': 0.7139835487661574, 'random': 0.5128672150411281}\n",
      "Running same_query_temperature_0.40_sample_n_30_01_18_07_06_54 (6/11)\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|█████████████████████████████████████████| 200/200 [02:02<00:00,  1.63it/s]\n",
      "the auc-roc is {'pr': 0.7300822561692127, 're': 0.7211515863689776, 'f1': 0.7252056404230317, 'ave': 0.7262044653349001, 'random': 0.4786133960047004}\n",
      "Running same_query_temperature_0.50_sample_n_30_11_21_01_50_46 (7/11)\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|█████████████████████████████████████████| 200/200 [02:05<00:00,  1.60it/s]\n",
      "the auc-roc is {'pr': 0.7507931844888366, 're': 0.7442420681551116, 'f1': 0.7482079905992949, 'ave': 0.7489717978848414, 'random': 0.5289071680376028}\n",
      "Running same_query_temperature_0.60_sample_n_30_01_18_14_45_30 (8/11)\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|█████████████████████████████████████████| 200/200 [02:08<00:00,  1.56it/s]\n",
      "the auc-roc is {'pr': 0.7472972972972974, 're': 0.7455346650998825, 'f1': 0.7478260869565218, 'ave': 0.7487074030552292, 'random': 0.495475910693302}\n",
      "Running same_query_temperature_0.70_sample_n_30_11_20_00_56_40 (9/11)\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|█████████████████████████████████████████| 200/200 [02:04<00:00,  1.60it/s]\n",
      "the auc-roc is {'pr': 0.7668625146886017, 're': 0.7708578143360753, 'f1': 0.7680376028202114, 'ave': 0.7691539365452409, 'random': 0.42620446533490014}\n",
      "Running same_query_temperature_0.80_sample_n_30_01_19_14_09_00 (10/11)\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|█████████████████████████████████████████| 200/200 [01:24<00:00,  2.38it/s]\n",
      "the auc-roc is {'pr': 0.7660399529964748, 're': 0.7710928319623972, 'f1': 0.7693301997649825, 'ave': 0.7702702702702703, 'random': 0.44524089306698006}\n",
      "Running same_query_temperature_0.90_sample_n_30_11_20_08_16_25 (11/11)\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      " 28%|███████████▊                              | 56/200 [00:22<00:54,  2.66it/s]Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      " 70%|████████████████████████████▋            | 140/200 [00:54<00:18,  3.17it/s]Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "100%|█████████████████████████████████████████| 200/200 [01:18<00:00,  2.56it/s]\n",
      "the auc-roc is {'pr': 0.7689776733254994, 're': 0.7822561692126909, 'f1': 0.7776733254994124, 'ave': 0.7792596944770858, 'random': 0.44776733254994117}\n"
     ]
    }
   ],
   "source": [
    "for i, SAMPLES_PATH in enumerate(SAMPLES_PATHS):\n",
    "    name = os.path.basename(SAMPLES_PATH).replace(\".csv\", \"\")\n",
    "    OUTPUT_PATH = f\"../scoring_results/same/{name}_results.csv\"\n",
    "    \n",
    "    print(f\"Running {name} ({i+1}/{len(SAMPLES_PATHS)})\")\n",
    "    \n",
    "    !python run_detection.py \\\n",
    "        --annotated {ANNOTATED_PATH} \\\n",
    "        --samples {SAMPLES_PATH}\\\n",
    "        --num_samples {NUM_SAMPLES} \\\n",
    "        --output {OUTPUT_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
